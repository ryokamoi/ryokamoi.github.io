
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    
    [{"authors":null,"categories":null,"content":"Ryo Kamoi is a CS Ph.D. student at Penn State University advised by Dr. Rui Zhang. He is broadly interested in Natural Language Processing, with a specific focus on building trustworthy NLP systems. He received his master’s degree in CS from UT Austin where he was advised by Dr. Greg Durrett, and received his bachelor’s degree in Statistics from Keio University where he was advised by Dr. Kei Kobayashi. He also interned at Amazon.\n Trustworthy NLP Systems Self-Detection and Self-Correction of Errors in LLM Responses [TACL\u0026#39;24, COLM\u0026#39;24] Fact Checking, Factuality Evaluation, and NLI [EMNLP\u0026#39;23, EACL\u0026#39;23] Vision-Language Models [arXiv\u0026#39;24]  ","date":1733961600,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1734361623,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Ryo Kamoi is a CS Ph.D. student at Penn State University advised by Dr. Rui Zhang. He is broadly interested in Natural Language Processing, with a specific focus on building trustworthy NLP systems.","tags":null,"title":"Ryo Kamoi","type":"authors"},{"authors":["Sarkar Snigdha Sarathi Das","Ryo Kamoi","Bo Pang","Yusen Zhang","Caiming Xiong","Rui Zhang"],"categories":[],"content":"","date":1733961600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1734361623,"objectID":"8e4299122ef2883673eb767d286cb734","permalink":"https://ryokamoi.github.io/publication/das-2024-greater/","publishdate":"2024-12-16T15:07:03.438093Z","relpermalink":"/publication/das-2024-greater/","section":"publication","summary":"","tags":["NLP"],"title":"GReaTer: Gradients over Reasoning Makes Smaller Language Models Strong Prompt Optimizers","type":"publication"},{"authors":["Ryo Kamoi","Yusen Zhang","Sarkar Snigdha Sarathi Das","Ranran Haoran Zhang","Rui Zhang"],"categories":[],"content":"","date":1733097600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733193512,"objectID":"91fe4f2610c9410659375df79c7c4db6","permalink":"https://ryokamoi.github.io/publication/kamoi-2024-visonlyqa/","publishdate":"2024-12-03T02:38:32.141507Z","relpermalink":"/publication/kamoi-2024-visonlyqa/","section":"publication","summary":"","tags":["NLP","CV"],"title":"VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information","type":"publication"},{"authors":null,"categories":null,"content":"","date":1733011200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1733011200,"objectID":"5375aee8a5b8d7f9e8f9aff17f1e47b1","permalink":"https://ryokamoi.github.io/project/2024_visonlyqa/","publishdate":"2024-12-01T00:00:00Z","relpermalink":"/project/2024_visonlyqa/","section":"project","summary":"Benchmark for evaluating LVLMs on visual perception questions on scientific figures.","tags":["Dataset"],"title":"VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information","type":"event"},{"authors":["Ryo Kamoi","Yusen Zhang","Nan Zhang","Jiawei Han","Rui Zhang"],"categories":[],"content":"","date":1730678400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717469110,"objectID":"d42acfeb4f2d6049e0d190978246d51d","permalink":"https://ryokamoi.github.io/publication/kamoi-2024-self-correction/","publishdate":"2024-11-04T02:45:08.892203Z","relpermalink":"/publication/kamoi-2024-self-correction/","section":"publication","summary":"","tags":["NLP"],"title":"When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs","type":"publication"},{"authors":["Renze Lou","Hanzi Xu","Sijia Wang","Jiangshu Du","Ryo Kamoi","Xiaoxin Lu","Jian Xie","Yuxuan Sun","Yusen Zhang","Jihyun Janice Ahn","Hongchao Fang","Zhuoyang Zou","Wenchao Ma","Xi Li","Kai Zhang","Congying Xia","Lifu Huang","Wenpeng Yin"],"categories":[],"content":"","date":1730160000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1730394133,"objectID":"ab4a80202d605a0a6008e61cf4e5108c","permalink":"https://ryokamoi.github.io/publication/lou-2024-aaar-10/","publishdate":"2024-10-31T17:02:13.125684Z","relpermalink":"/publication/lou-2024-aaar-10/","section":"publication","summary":"","tags":["NLP"],"title":"AAAR-1.0: Assessing AI's Potential to Assist Research","type":"publication"},{"authors":null,"categories":"talk","content":"Lecture about self-correction of LLMs based on our survey paper “When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs” .\n松尾・岩澤研究室の松尾研DL輪読会 x 大規模言語モデル講座の特別回として「LLMの自己修正 〜OpenAI o1の関連研究〜」と題してトークの機会をいただきました。動画およびスライドも公開していただきました。LLMの自己修正 (Self-Correction) をテーマとして、OpenAI o1に至るまでの推論時にLLMの出力を向上する技術を紹介しました。\n    2024Fall 大規模言語モデル(LLM)講座 特別回：LLMの自己修正〜OpenAI o1 の関連研究〜 by @matsuo-lab_llm  ","date":1729123200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1729123200,"objectID":"6c85dc118c2337ce91ac67e72acf72ad","permalink":"https://ryokamoi.github.io/talk/matsuo-iwasawa-lab-at-the-university-of-tokyo-llm%E8%AC%9B%E5%BA%A7-ja/","publishdate":"2024-10-17T00:00:00Z","relpermalink":"/talk/matsuo-iwasawa-lab-at-the-university-of-tokyo-llm%E8%AC%9B%E5%BA%A7-ja/","section":"event","summary":"Lecture about self-correction of LLMs based on our survey paper \"When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs\"","tags":null,"title":"Matsuo-Iwasawa Lab at the University of Tokyo (LLM講座, ja)","type":"event"},{"authors":["Ryo Kamoi","Sarkar Snigdha Sarathi Das","Renze Lou","Jihyun Janice Ahn","Yilun Zhao","Xiaoxin Lu","Nan Zhang","Yusen Zhang","Ranran Haoran Zhang","Sujeeth Reddy Vummanthala","Salika Dave","Shaobo Qin","Arman Cohan","Wenpeng Yin","Rui Zhang"],"categories":[],"content":"","date":1728259200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712282640,"objectID":"d8b3cd9b36ad5b1d89ec489090f6b56c","permalink":"https://ryokamoi.github.io/publication/kamoi-2024-realmistake/","publishdate":"2024-04-05T02:04:00.554112Z","relpermalink":"/publication/kamoi-2024-realmistake/","section":"publication","summary":"","tags":["NLP"],"title":"Evaluating LLMs at Detecting Errors in LLM Responses","type":"publication"},{"authors":null,"categories":null,"content":"This is a note from my experience in 2024. Please check the latest information from the official TACL website.\nThe TACL submission process is a bit complex compared to recent conference submissions on OpenReview, but the editors (and editor assistants) are very helpful and responsive.\nTimeline  We received the initial decision (B-decision) within two months after the initial submission The revision process is very responsive and quick. I received responses in about one week for each revision (B-Decision revision and final submission).  Initial Submission  Refer to https://transacl.org/index.php/tacl/about/submissions. From 2024, we can add appendices to the paper, but we can only include (1) experimental settings such as pre-processing decisions, model parameters, feature templates or (2) complementary results (images, tables).  Refer to https://transacl.org/index.php/tacl/announcement/view/105. (the LaTeX template is not updated for this new policy)    Preprints  From 2024, there is no anonymity period. There is no embargo period in TACL https://direct.mit.edu/journals/pages/authors#reprints.  B-decision Revision  Most accepted papers receive B-decision (conditional accept) https://www.aclweb.org/adminwiki/index.php/2022Q1_Reports:_TACL_Journal. You will send an email with the revised version to the editors (not on the submission system you use for the initial submission). There is no official format for the cover letter. I just made it by myself.  Final Submission  Refer to https://transacl.org/ojs/index.php/tacl/author/instructions/proof. The final version should not have any tables or figures in the first page.  Conference Presentation  We can present TACL papers in the ACL conferences (optional). Each conference has its deadline for the A-decision and final version submission. TACL does not guarantee the decisions before the conference deadlines.  Example: EMNLP 2024 - TACL acceptance/final-version deadlines   After the final submission, editorial assistants will send you emails about the conference presentation after the conference deadlines.  ","date":1724457600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1724457600,"objectID":"e9931ec3d2075f7ee3ebf36b9ee7413f","permalink":"https://ryokamoi.github.io/post/2024-08-24-tacl/","publishdate":"2024-08-24T00:00:00Z","relpermalink":"/post/2024-08-24-tacl/","section":"post","summary":"This is a note from my experience in 2024. Please check the latest information from the official TACL website.\nThe TACL submission process is a bit complex compared to recent conference submissions on OpenReview, but the editors (and editor assistants) are very helpful and responsive.","tags":null,"title":"TACL Submission Process (2024)","type":"post"},{"authors":["Jihyun Janice Ahn","Ryo Kamoi","Lu Cheng","Rui Zhang","Wenpeng Yin"],"categories":[],"content":"","date":1719446400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1721400775,"objectID":"974680fb55b5de43dd867a7052da2e31","permalink":"https://ryokamoi.github.io/publication/ahn-2024-directinverse/","publishdate":"2024-07-19T14:52:54.796768Z","relpermalink":"/publication/ahn-2024-directinverse/","section":"publication","summary":"","tags":["NLP"],"title":"Direct-Inverse Prompting: Analyzing LLMs' Discriminative Capacity in Self-Improving Generation","type":"publication"},{"authors":null,"categories":null,"content":"","date":1717372800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1717372800,"objectID":"1139ba3fb443d3db0ac8d8d7a99086a3","permalink":"https://ryokamoi.github.io/project/2024_realmistake/","publishdate":"2024-06-03T00:00:00Z","relpermalink":"/project/2024_realmistake/","section":"project","summary":"We critically survey broad papers and discuss the conditions required for successful self-correction.","tags":["Survey"],"title":"Critical Survey of Self-Correction of LLMs","type":"event"},{"authors":["Yilun Zhao","Yitao Long","Hongjun Liu","Linyong Nan","Lyuhao Chen","Ryo Kamoi","Yixin Liu","Xiangru Tang","Rui Zhang","Arman Cohan"],"categories":[],"content":"","date":1717200000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1700187241,"objectID":"734adf86e2f402b504aa05b069f5352a","permalink":"https://ryokamoi.github.io/publication/zhao-2023-docmatheval/","publishdate":"2023-11-17T02:14:00.903638Z","relpermalink":"/publication/zhao-2023-docmatheval/","section":"publication","summary":"","tags":["NLP"],"title":"DocMath-Eval: Evaluating Numerical Reasoning Capabilities of LLMs in Understanding Long Documents with Tabular Data","type":"publication"},{"authors":["Yusen Zhang","Nan Zhang","Yixin Liu","Alexander Fabbri","Junru Liu","Ryo Kamoi","Xiaoxin Lu","Caiming Xiong","Jieyu Zhao","Dragomir Radev","Kathleen McKeown","Rui Zhang"],"categories":[],"content":"","date":1717200000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1700088919,"objectID":"e439ce262a87a855dd25ef55b61afda6","permalink":"https://ryokamoi.github.io/publication/zhang-2023-fair/","publishdate":"2023-11-15T22:55:19.233506Z","relpermalink":"/publication/zhang-2023-fair/","section":"publication","summary":"","tags":["NLP"],"title":"Fair Abstractive Summarization of Diverse Perspectives","type":"publication"},{"authors":null,"categories":null,"content":"","date":1712188800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1712188800,"objectID":"f90938648d3212b138d9c5ee738b86b5","permalink":"https://ryokamoi.github.io/project/2024_self-correction-survey/","publishdate":"2024-04-04T00:00:00Z","relpermalink":"/project/2024_self-correction-survey/","section":"project","summary":"Benchmark including errors in responses of GPT-4 and Llama 2 70B annotated by experts.","tags":["Dataset"],"title":"ReaLMistake: Benchmark for Evaluating LLMs at Detecting Errors in LLM Responses","type":"event"},{"authors":["Ryo Kamoi","Tanya Goyal","Juan Diego Rodriguez","Greg Durrett"],"categories":[],"content":"","date":1701820800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696714379,"objectID":"966fcec2dde527cdbec6b76943556b56","permalink":"https://ryokamoi.github.io/publication/kamoi-2023-wice/","publishdate":"2023-10-07T21:32:59.280863Z","relpermalink":"/publication/kamoi-2023-wice/","section":"publication","summary":"Models for textual entailment have increasingly been applied to settings like fact-checking, presupposition verification in question answering, and validating that generation models' outputs are faithful to a source. However, such applications are quite far from the settings that existing datasets are constructed in. We propose WiCE, a new textual entailment dataset centered around verifying claims in text, built on real-world claims and evidence in Wikipedia with fine-grained annotations. We collect sentences in Wikipedia that cite one or more webpages and annotate whether the content on those pages entails those sentences. Negative examples arise naturally, from slight misinterpretation of text to minor aspects of the sentence that are not attested in the evidence. Our annotations are over sub-sentence units of the hypothesis, decomposed automatically by GPT-3, each of which is labeled with a subset of evidence sentences from the source document. We show that real claims in our dataset involve challenging verification problems, and we benchmark existing approaches on this dataset. In addition, we show that reducing the complexity of claims by decomposing them by GPT-3 can improve entailment models' performance on various domains.","tags":["nlp"],"title":"WiCE: Real-World Entailment for Claims in Wikipedia","type":"publication"},{"authors":null,"categories":"talk","content":"Talk about our paper “WiCE: Real-World Entailment for Claims in Wikipedia”.\n   ","date":1701216000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1701216000,"objectID":"74bdd6d666d7807467a6b06d9fec3a8c","permalink":"https://ryokamoi.github.io/talk/nlp-colloquium-jp-nlp%E3%82%B3%E3%83%AD%E3%82%AD%E3%82%A6%E3%83%A0-ja/","publishdate":"2023-11-29T00:00:00Z","relpermalink":"/talk/nlp-colloquium-jp-nlp%E3%82%B3%E3%83%AD%E3%82%AD%E3%82%A6%E3%83%A0-ja/","section":"event","summary":"Talk about our paper \"WiCE Real-World Entailment for Claims in Wikipedia\"","tags":null,"title":"NLP Colloquium JP (NLPコロキウム, ja)","type":"event"},{"authors":null,"categories":"talk","content":"Talk about our papers “Shortcomings of Question Answering Based Factuality Frameworks for Error Localization”  and “WiCE: Real-World Entailment for Claims in Wikipedia”.\n   ","date":1688342400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1688342400,"objectID":"3fd4cf6b4e0f153e064f1335c853f9a8","permalink":"https://ryokamoi.github.io/talk/nagoya-nlp-seminar-at-nagoya-university-%E5%90%8D%E5%8F%A4%E5%B1%8Bnlp%E3%82%BB%E3%83%9F%E3%83%8A%E3%83%BC-ja/","publishdate":"2023-07-03T00:00:00Z","relpermalink":"/talk/nagoya-nlp-seminar-at-nagoya-university-%E5%90%8D%E5%8F%A4%E5%B1%8Bnlp%E3%82%BB%E3%83%9F%E3%83%8A%E3%83%BC-ja/","section":"event","summary":"Talk about our papers \"Shortcomings of Question Answering Based Factuality Frameworks for Error Localization\" and \"WiCE Real-World Entailment for Claims in Wikipedia\"","tags":null,"title":"Nagoya NLP Seminar at Nagoya University (名古屋NLPセミナー, ja)","type":"event"},{"authors":["Ryo Kamoi","Tanya Goyal","Greg Durrett"],"categories":[],"content":"   ","date":1682899200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1684027078,"objectID":"96c03ff4f67c9f16417f8927b07992e5","permalink":"https://ryokamoi.github.io/publication/kamoi-2023-shortcomings/","publishdate":"2023-05-14T01:17:58.850182Z","relpermalink":"/publication/kamoi-2023-shortcomings/","section":"publication","summary":"Despite recent progress in abstractive summarization, models often generate summaries with factual errors. Numerous approaches to detect these errors have been proposed, the most popular of which are question answering (QA)-based factuality metrics. These have been shown to work well at predicting summary-level factuality and have potential to localize errors within summaries, but this latter capability has not been systematically evaluated in past research. In this paper, we conduct the first such analysis and find that, contrary to our expectations, QA-based frameworks fail to correctly identify error spans in generated summaries and are outperformed by trivial exact match baselines. Our analysis reveals a major reason for such poor localization: questions generated by the QG module often inherit errors from non-factual summaries which are then propagated further into downstream modules. Moreover, even human-in-the-loop question generation cannot easily offset these problems. Our experiments conclusively show that there exist fundamental issues with localization using the QA framework which cannot be fixed solely by stronger QA and QG models.","tags":["nlp"],"title":"Shortcomings of Question Answering Based Factuality Frameworks for Error Localization","type":"publication"},{"authors":["Ryo Kamoi","Takumi Iida","Kaname Tomite"],"categories":[],"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669572023,"objectID":"ff19ffbda4599a8030c8f5a4120ea85b","permalink":"https://ryokamoi.github.io/publication/kamoi-2021/","publishdate":"2023-01-23T02:19:34.156061Z","relpermalink":"/publication/kamoi-2021/","section":"publication","summary":"Detecting unknown objects such as lost cargo is essential for improving the safety of self-driving cars. This is the first work focusing on reducing the computational cost of discrepancy networks for unknown object detection on monocular camera images. We propose an efficient discrepancy networks based solely on semantic segmentation, which has 50% fewer parameters and is 140% faster inference speed compared to an existing method, while improving detection performance by a large margin. In a major departure from prior work, we remove GANs from discrepancy networks. While previous studies have used GANs as a necessary component, our model outperforms them without using it. We further improve detection performance by analyzing intermediate representations and introducing feature selection and deep supervision. Our experiments on three datasets for obstacle detection show significant improvement of more than 5% in AUROC.","tags":["Out-of-Distribution Detection"],"title":"Efficient Unknown Object Detection with Discrepancy Networks for Semantic Segmentation","type":"publication"},{"authors":null,"categories":null,"content":"Influence function for neural networks is proposed in the ICML2017 best paper (Wei Koh \u0026amp; Liang, 2017). However, to the best of my knowledge, there is no generic PyTorch implementation with reliable test codes. Based on some existing implementations, I’m developing reliable Pytorch implementation of influence function.\n https://github.com/ryokamoi/pytorch_influence_functions https://github.com/ryokamoi/test_pytorch_influence_functions  My repositories are forks of the following great work.\n https://github.com/nimarb/pytorch_influence_functions https://github.com/dedeswim/pytorch_influence_functions https://github.com/nayopu/influence_function_with_lissa  ","date":1592438400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1592438400,"objectID":"9184d4b565463623c3a0db16a396cf5b","permalink":"https://ryokamoi.github.io/post/2020-06-18/","publishdate":"2020-06-18T00:00:00Z","relpermalink":"/post/2020-06-18/","section":"post","summary":"Influence function for neural networks is proposed in the ICML2017 best paper (Wei Koh \u0026 Liang, 2017). However, to the best of my knowledge, there is no generic PyTorch implementation with reliable test codes.","tags":null,"title":"PyTorch Implementation of Influence Function","type":"post"},{"authors":["Katsuhiro Endo","Ryo Kamoi","Kenji Yasuoka"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669572023,"objectID":"c5b6e1d1b061613b104c2b39304c6f20","permalink":"https://ryokamoi.github.io/publication/endo-2020/","publishdate":"2023-01-23T02:19:33.606403Z","relpermalink":"/publication/endo-2020/","section":"publication","summary":"","tags":["others"],"title":"Alternative methods for fast and stable GAN","type":"publication"},{"authors":["Ryo Kamoi","Kei Kobayashi"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669572023,"objectID":"03d33ca9da64144e529edebf4f41cbab","permalink":"https://ryokamoi.github.io/publication/kamoi-2020/","publishdate":"2023-01-23T02:19:34.019352Z","relpermalink":"/publication/kamoi-2020/","section":"publication","summary":"","tags":["Out-of-Distribution Detection"],"title":"Out-of-Distribution Detection with Likelihoods Assigned by Deep Generative Models Using Multimodal Prior Distributions","type":"publication"},{"authors":["Ryo Kamoi","Kei Kobayashi"],"categories":[],"content":"","date":1577836800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669572023,"objectID":"f75436fcd2aef06c7522e29e064ca06e","permalink":"https://ryokamoi.github.io/publication/kamoi-2020-a/","publishdate":"2023-01-23T02:19:33.741756Z","relpermalink":"/publication/kamoi-2020-a/","section":"publication","summary":"The Mahalanobis distance-based confidence score, a recently proposed anomaly detection method for pre-trained neural classifiers, achieves state-of-the-art performance on both out-of-distribution (OoD) and adversarial examples detection. This work analyzes why this method exhibits such strong performance in practical settings while imposing an implausible assumption; namely, that class conditional distributions of pre-trained features have tied covariance. Although the Mahalanobis distance-based method is claimed to be motivated by classification prediction confidence, we find that its superior performance stems from information not useful for classification. This suggests that the reason the Mahalanobis confidence score works so well is mistaken, and makes use of different information from ODIN, another popular OoD detection method based on prediction confidence. This perspective motivates us to combine these two methods, and the combined detector exhibits improved performance and robustness. These findings provide insight into the behavior of neural classifiers in response to anomalous inputs.","tags":["Out-of-Distribution Detection"],"title":"Why is the Mahalanobis Distance Effective for Anomaly Detection?","type":"publication"},{"authors":null,"categories":null,"content":"I have presented my research about implicit curve approximation in Meeting of the Minds 2019 (Undergraduate Research Symposium at CMU).\n My poster presented at Meeting of the Minds 2019 Implementation of present implicit curve approximation methods  Our method is based on the topologically faithful implicit curve approximation method proposed by Keren (2004). One shortcomming of the method is that it requires high-degree non-linear optimization. We propose a method to transform the problem into contrained least squares, which can be solved by quadratic programming.\nShortcommings of our method are\n It requires an ordering of the data points. It requires control points. The representation power is not sufficient.  References\n Keren, D. (2004). Topologically Faithful Fitting of Simple Closed Curves. IEEE Transactions on Pattern Analysis and Machine Intelligence, 26(1), 118–123. https://doi.org/10.1109/TPAMI.2004.1261095  ","date":1557532800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557532800,"objectID":"a4a15c12604372976c5bdef6a6c3a8a3","permalink":"https://ryokamoi.github.io/post/2019-05-11/","publishdate":"2019-05-11T00:00:00Z","relpermalink":"/post/2019-05-11/","section":"post","summary":"I have presented my research about implicit curve approximation in Meeting of the Minds 2019 (Undergraduate Research Symposium at CMU).\n My poster presented at Meeting of the Minds 2019 Implementation of present implicit curve approximation methods  Our method is based on the topologically faithful implicit curve approximation method proposed by Keren (2004).","tags":null,"title":"Topologically Faithful Implicit Curve Approximation by Constrained Least Squares","type":"post"},{"authors":["Ryo Kamoi","Kei Kobayashi"],"categories":[],"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669572023,"objectID":"a23dc13939a7edc34438bfcbaeda708e","permalink":"https://ryokamoi.github.io/publication/kamoi-2019/","publishdate":"2023-01-23T02:19:34.306317Z","relpermalink":"/publication/kamoi-2019/","section":"publication","summary":"Recent work has shown that deep generative models assign higher likelihood to out-of-distribution inputs than to training data. We show that a factor underlying this phenomenon is a mismatch between the nature of the prior distribution and that of the data distribution, a problem found in widely used deep generative models such as VAEs and Glow. While a typical choice for a prior distribution is a standard Gaussian distribution, properties of distributions of real data sets may not be consistent with a unimodal prior distribution. This paper focuses on the relationship between the choice of a prior distribution and the likelihoods assigned to out-of-distribution inputs. We propose the use of a mixture distribution as a prior to make likelihoods assigned by deep generative models sensitive to out-of-distribution inputs. Furthermore, we explain the theoretical advantages of adopting a mixture distribution as the prior, and we present experimental results to support our claims. Finally, we demonstrate that a mixture prior lowers the out-of-distribution likelihood with respect to two pairs of real image data sets: Fashion-MNIST vs. MNIST and CI-FAR10 vs. SVHN.","tags":["Out-of-Distribution Detection"],"title":"Likelihood Assignment for Out-of-Distribution Inputs in Deep Generative Models is Sensitive to Prior Distribution Choice","type":"publication"},{"authors":null,"categories":null,"content":" “Generating Sentences from a Continuous Space” (Bowman et al., 2015)  https://github.com/ryokamoi/original_textvae Implementation of the first work on VAE for text. This model is a simple LSTM-LSTM seq2seq model with word dropout.   “Improved Variational Autoencoders for Text Modeling using Dilated Convolutions” (Yang, Hu, Salakhutdinov, \u0026amp; Taylor, 2017)  https://github.com/ryokamoi/dcnn_textvae Implementation of an improved model of VAE for text. This model uses dilated CNN as a decoder to control the capacity of the decoder.   “A Hybrid Convolutional Variational Autoencoder for Text Generation” (Semeniuta, Severyn, \u0026amp; Barth, 2017)  https://github.com/ryokamoi/hybrid_textvae Implementation of VAE for text with hybrid structure. This model tries to solve the problem called “posterior collapse” with an auxiliary task to predict a sentence with CNN without teacher forcing.    References\n Bowman, S. R., Vilnis, L., Vinyals, O., Dai, A. M., Jozefowicz, R., \u0026amp; Bengio, S. (2015). Generating Sentences from a Continuous Space. In SIGNLL Conference on Computational Natural Language Learning (CoNLL). Yang, Z., Hu, Z., Salakhutdinov, R., \u0026amp; Taylor, B.-K. (2017). Improved Variational Autoencoders for Text Modeling using Dilated Convolutions. In International Conference on Machine Learning (ICML). Semeniuta, S., Severyn, A., \u0026amp; Barth, E. (2017). A Hybrid Convolutional Variational Autoencoder for Text Generation. In Conference on Empirical Methods in Natural Language Processing (EMNLP) (pp. 627–637).  ","date":1534636800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1534636800,"objectID":"d2fb98fdbb6e2b246fbfd979fa905ae6","permalink":"https://ryokamoi.github.io/post/2018-08-19/","publishdate":"2018-08-19T00:00:00Z","relpermalink":"/post/2018-08-19/","section":"post","summary":"“Generating Sentences from a Continuous Space” (Bowman et al., 2015)  https://github.com/ryokamoi/original_textvae Implementation of the first work on VAE for text. This model is a simple LSTM-LSTM seq2seq model with word dropout.","tags":null,"title":"Implementations of VAEs for Text","type":"post"}]