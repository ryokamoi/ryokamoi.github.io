@inproceedings{Endo2020,
    author = {Endo, Katsuhiro and Kamoi, Ryo and Yasuoka, Kenji},
    booktitle = {MIRU},
    title = {{Alternative methods for fast and stable GAN}},
    year = {2020}
}
@unpublished{Kamoi2020a,
    abstract = {The Mahalanobis distance-based confidence score, a recently proposed anomaly detection method for pre-trained neural classifiers, achieves state-of-the-art performance on both out-of-distribution (OoD) and adversarial examples detection. This work analyzes why this method exhibits such strong performance in practical settings while imposing an implausible assumption; namely, that class conditional distributions of pre-trained features have tied covariance. Although the Mahalanobis distance-based method is claimed to be motivated by classification prediction confidence, we find that its superior performance stems from information not useful for classification. This suggests that the reason the Mahalanobis confidence score works so well is mistaken, and makes use of different information from ODIN, another popular OoD detection method based on prediction confidence. This perspective motivates us to combine these two methods, and the combined detector exhibits improved performance and robustness. These findings provide insight into the behavior of neural classifiers in response to anomalous inputs.},
    archivePrefix = {arXiv},
    arxivId = {2003.00402},
    author = {Kamoi, Ryo and Kobayashi, Kei},
    journal = {arXiv preprint arXiv:2003.00402},
    title = {{Why is the Mahalanobis Distance Effective for Anomaly Detection?}},
    year = {2020}
}
@inproceedings{Kamoi2023shortcomings,
    title = "Shortcomings of Question Answering Based Factuality Frameworks for Error Localization",
    author = "Kamoi, Ryo and Goyal, Tanya  and Durrett, Greg",
    booktitle = "Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics",
    month = may,
    year = "2023",
    address = "Dubrovnik, Croatia",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.eacl-main.11",
    pages = "132--146",
    abstract = "Despite recent progress in abstractive summarization, models often generate summaries with factual errors. Numerous approaches to detect these errors have been proposed, the most popular of which are question answering (QA)-based factuality metrics. These have been shown to work well at predicting summary-level factuality and have potential to localize errors within summaries, but this latter capability has not been systematically evaluated in past research. In this paper, we conduct the first such analysis and find that, contrary to our expectations, QA-based frameworks fail to correctly identify error spans in generated summaries and are outperformed by trivial exact match baselines. Our analysis reveals a major reason for such poor localization: questions generated by the QG module often inherit errors from non-factual summaries which are then propagated further into downstream modules. Moreover, even human-in-the-loop question generation cannot easily offset these problems. Our experiments conclusively show that there exist fundamental issues with localization using the QA framework which cannot be fixed solely by stronger QA and QG models.",
}
@inproceedings{Kamoi2020,
    author = {Kamoi, Ryo and Kobayashi, Kei},
    booktitle = {The AAAI's Workshop on Artificial Intelligence Safety},
    title = {{Out-of-Distribution Detection with Likelihoods Assigned by Deep Generative Models Using Multimodal Prior Distributions}},
    url = {https://ceur-ws.org/Vol-2560/paper2.pdf},
    year = {2020}
}
@inproceedings{Kamoi2021,
    abstract = {Detecting unknown objects such as lost cargo is essential for improving the safety of self-driving cars. This is the first work focusing on reducing the computational cost of discrepancy networks for unknown object detection on monocular camera images. We propose an efficient discrepancy networks based solely on semantic segmentation, which has 50% fewer parameters and is 140% faster inference speed compared to an existing method, while improving detection performance by a large margin. In a major departure from prior work, we remove GANs from discrepancy networks. While previous studies have used GANs as a necessary component, our model outperforms them without using it. We further improve detection performance by analyzing intermediate representations and introducing feature selection and deep supervision. Our experiments on three datasets for obstacle detection show significant improvement of more than 5% in AUROC.},
    author = {Kamoi, Ryo and Iida, Takumi and Tomite, Kaname},
    booktitle = {NeurIPS Workshop on Machine Learning for Autonomous Driving},
    title = {{Efficient Unknown Object Detection with Discrepancy Networks for Semantic Segmentation}},
    url = {https://ml4ad.github.io/files/papers2021/Efficient Unknown Object Detection with Discrepancy Networks for Semantic Segmentation.pdf},
    year = {2021}
}
@unpublished{Kamoi2019,
    abstract = {Recent work has shown that deep generative models assign higher likelihood to out-of-distribution inputs than to training data. We show that a factor underlying this phenomenon is a mismatch between the nature of the prior distribution and that of the data distribution, a problem found in widely used deep generative models such as VAEs and Glow. While a typical choice for a prior distribution is a standard Gaussian distribution, properties of distributions of real data sets may not be consistent with a unimodal prior distribution. This paper focuses on the relationship between the choice of a prior distribution and the likelihoods assigned to out-of-distribution inputs. We propose the use of a mixture distribution as a prior to make likelihoods assigned by deep generative models sensitive to out-of-distribution inputs. Furthermore, we explain the theoretical advantages of adopting a mixture distribution as the prior, and we present experimental results to support our claims. Finally, we demonstrate that a mixture prior lowers the out-of-distribution likelihood with respect to two pairs of real image data sets: Fashion-MNIST vs. MNIST and CI-FAR10 vs. SVHN.},
    archivePrefix = {arXiv},
    arxivId = {1911.06515},
    author = {Kamoi, Ryo and Kobayashi, Kei},
    journal = {arXiv preprint arXiv:1911.06515},
    title = {{Likelihood Assignment for Out-of-Distribution Inputs in Deep Generative Models is Sensitive to Prior Distribution Choice}},
    year = {2019}
}
@inproceedings{Kamoi2023wice,
    title = "{W}i{CE}: Real-World Entailment for Claims in {W}ikipedia",
    author = "Kamoi, Ryo  and
      Goyal, Tanya  and
      Rodriguez, Juan  and
      Durrett, Greg",
    editor = "Bouamor, Houda  and
      Pino, Juan  and
      Bali, Kalika",
    booktitle = "Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.emnlp-main.470",
    pages = "7561--7583",
    abstract = "Textual entailment models are increasingly applied in settings like fact-checking, presupposition verification in question answering, or summary evaluation. However, these represent a significant domain shift from existing entailment datasets, and models underperform as a result. We propose WiCE, a new fine-grained textual entailment dataset built on natural claim and evidence pairs extracted from Wikipedia. In addition to standard claim-level entailment, WiCE provides entailment judgments over sub-sentence units of the claim, and a minimal subset of evidence sentences that support each subclaim. To support this, we propose an automatic claim decomposition strategy using GPT-3.5 which we show is also effective at improving entailment models{'} performance on multiple datasets at test time. Finally, we show that real claims in our dataset involve challenging verification and retrieval problems that existing models fail to address.",
}
@unpublished{zhang2023fair,
    title={Fair Abstractive Summarization of Diverse Perspectives}, 
    author={Yusen Zhang and Nan Zhang and Yixin Liu and Alexander Fabbri and Junru Liu and Ryo Kamoi and Xiaoxin Lu and Caiming Xiong and Jieyu Zhao and Dragomir Radev and Kathleen McKeown and Rui Zhang},
    year={2023},
    journal = {arXiv preprint arXiv:2311.07884},
}
@unpublished{zhao2023docmatheval,
    title={DocMath-Eval: Evaluating Numerical Reasoning Capabilities of LLMs in Understanding Long Documents with Tabular Data}, 
    author={Yilun Zhao and Yitao Long and Hongjun Liu and Linyong Nan and Lyuhao Chen and Ryo Kamoi and Yixin Liu and Xiangru Tang and Rui Zhang and Arman Cohan},
    year={2023},
    journal = {arXiv preprint arXiv:2311.09805},
}
@inproceedings{kamoi2024realmistake,
    title={Evaluating {LLM}s at Detecting Errors in {LLM} Responses},
    author={Ryo Kamoi and Sarkar Snigdha Sarathi Das and Renze Lou and Jihyun Janice Ahn and Yilun Zhao and Xiaoxin Lu and Nan Zhang and Yusen Zhang and Haoran Ranran Zhang and Sujeeth Reddy Vummanthala and Salika Dave and Shaobo Qin and Arman Cohan and Wenpeng Yin and Rui Zhang},
    booktitle={First Conference on Language Modeling},
    year={2024},
    url={https://openreview.net/forum?id=dnwRScljXr}
}
@article{kamoi2024self-correction,
    author = {Kamoi, Ryo and Zhang, Yusen and Zhang, Nan and Han, Jiawei and Zhang, Rui},
    title = "{When Can LLMs Actually Correct Their Own Mistakes? A Critical Survey of Self-Correction of LLMs}",
    journal = {Transactions of the Association for Computational Linguistics},
    volume = {12},
    pages = {1417-1440},
    year = {2024},
    month = {11},
    issn = {2307-387X},
    doi = {10.1162/tacl_a_00713},
    url = {https://doi.org/10.1162/tacl\_a\_00713},
    eprint = {https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl\_a\_00713/2478635/tacl\_a\_00713.pdf},
}
@unpublished{ahn2024directinverse,
    title={Direct-Inverse Prompting: Analyzing LLMs' Discriminative Capacity in Self-Improving Generation}, 
    author={Jihyun Janice Ahn and Ryo Kamoi and Lu Cheng and Rui Zhang and Wenpeng Yin},
    year={2024},
    journal={arXiv preprint arXiv:2407.11017},
}
@unpublished{lou2024aaar10,
    title={AAAR-1.0: Assessing AI's Potential to Assist Research}, 
    author={Renze Lou and Hanzi Xu and Sijia Wang and Jiangshu Du and Ryo Kamoi and Xiaoxin Lu and Jian Xie and Yuxuan Sun and Yusen Zhang and Jihyun Janice Ahn and Hongchao Fang and Zhuoyang Zou and Wenchao Ma and Xi Li and Kai Zhang and Congying Xia and Lifu Huang and Wenpeng Yin},
    year={2024},
    journal={arXiv preprint arXiv:2410.22394},
}
@unpublished{kamoi2024visonlyqa,
    title={VisOnlyQA: Large Vision Language Models Still Struggle with Visual Perception of Geometric Information}, 
    author={Ryo Kamoi and Yusen Zhang and Sarkar Snigdha Sarathi Das and Ranran Haoran Zhang and Rui Zhang},
    year={2024},
    journal={arXiv preprint arXiv:2412.00947},
}
@inproceedings{das2024greater,
title={{GR}eaTer: Gradients Over Reasoning Makes Smaller Language Models Strong Prompt Optimizers},
author={Sarkar Snigdha Sarathi Das and Ryo Kamoi and Bo Pang and Yusen Zhang and Caiming Xiong and Rui Zhang},
booktitle={The Thirteenth International Conference on Learning Representations},
year={2025},
url={https://openreview.net/forum?id=fWRBheSJth}
}
